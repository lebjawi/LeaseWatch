# LeaseWatch Python Project

**Automated Apartment Pricing Tracker for Camden Dunwoody & Perimeter Gardens**

> "Stop hunting for deals. Start watching them."

Track live floor plan pricing daily using Playwright and cloud automation with **zero manual work**.

---

## ğŸ“Œ Overview

**LeaseWatch** is a Python-based backend project that monitors apartment pricing daily for luxury apartment communities. It uses **Playwright** to scrape dynamic floor plan pricing and outputs logs or reports for 1B/1B and 2B/2B units.

**Current Target Properties:**
- **Camden Dunwoody**
- **The Columns at Lake Ridge**
- **Drift Dunwoody**

---

## ğŸ”§ Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | Python 3.13+ |
| Headless Browser | Playwright |
| Web Framework | aiohttp (optional server) |
| Data Processing | Pydantic |
| Storage | Local JSON |
| Logging | Python logging |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Python Script    â”‚
â”‚   or HTTP Server   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Playwright Scrapers â”‚
â”‚ - Camden           â”‚
â”‚ - Columns          â”‚
â”‚ - Drift            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Processing     â”‚
â”‚ & Report Generation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Local JSON Storage  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Installation

### Prerequisites
- Python 3.13 or higher
- pip package manager

### Setup Steps

1. **Clone the repository:**
   ```bash
   git clone https://github.com/lebjawi/LeaseWatch.git
   cd LeaseWatch
   ```

2. **Create and activate virtual environment:**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Install Playwright browsers:**
   ```bash
   python -m playwright install chromium
   ```

---

## ï¿½ Usage

### Command Line Interface

**Run once (scrape all properties):**
```bash
python main.py
```

**Start HTTP Server:**
```bash
python server.py
```

### HTTP API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API documentation |
| GET | `/health` | Health check |
| POST | `/scrape` | Trigger scraping |
| GET | `/data` | Get latest data |
| GET | `/report` | Get reports |
| GET | `/dates` | Available dates |
| GET | `/history` | Property history |

### Example API Calls

```bash
# Health check
curl http://localhost:8000/health

# Trigger scraping
curl -X POST http://localhost:8000/scrape

# Get latest data
curl http://localhost:8000/data

# Get daily report
curl http://localhost:8000/report?type=daily

# Get property comparison
curl http://localhost:8000/report?type=comparison

# Get property history
curl http://localhost:8000/history?property=Camden%20Dunwoody&days=30
```

---

## ğŸ“Š Sample Output

```
ğŸ¡ LeaseWatch - Starting apartment pricing tracker...
ğŸ“… Date: 2025-08-02T10:30:00

ğŸ” Phase 1: Data Collection
==================================================
ğŸ¢ Scraping Camden Dunwoody...
âœ… Camden Dunwoody scraping completed: 12 floor plans found

ğŸ¢ Scraping The Columns at Lake Ridge...
âœ… The Columns at Lake Ridge scraping completed: 8 floor plans found

ğŸ¢ Scraping Drift Dunwoody...
âœ… Drift Dunwoody scraping completed: 6 floor plans found

ğŸ“Š DAILY SUMMARY
==================================================
ğŸ“… Date: 2025-08-02
ğŸ¢ Properties Scraped: 3
ğŸ“‹ Total Floor Plans: 26
ğŸ’° Price Range: $1,400 - $3,200
ğŸ’µ Average Price: $2,150

ğŸ  Properties:
   â€¢ Camden Dunwoody: 12 floor plans
   â€¢ The Columns at Lake Ridge: 8 floor plans
   â€¢ Drift Dunwoody: 6 floor plans
```

---

## ğŸ“ Project Structure

```
LeaseWatch/
â”œâ”€â”€ main.py                 # Main application entry point
â”œâ”€â”€ server.py              # HTTP server (optional)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ data/                 # Local data storage
â”‚   â”œâ”€â”€ daily/           # Daily scraped data
â”‚   â”œâ”€â”€ reports/         # Generated reports
â”‚   â””â”€â”€ raw/             # Raw debug data
â””â”€â”€ src/
    â”œâ”€â”€ scrapers/        # Web scrapers
    â”‚   â”œâ”€â”€ camden.py
    â”‚   â”œâ”€â”€ columns.py
    â”‚   â””â”€â”€ drift.py
    â”œâ”€â”€ services/        # Business logic
    â”‚   â”œâ”€â”€ storage.py
    â”‚   â””â”€â”€ report.py
    â”œâ”€â”€ types/           # Data models
    â”‚   â””â”€â”€ types.py
    â””â”€â”€ utils/           # Utilities
        â”œâ”€â”€ data_processor.py
        â”œâ”€â”€ report_generator.py
        â””â”€â”€ logger.py
```

---

## ğŸ”§ Configuration

### Environment Variables (Optional)

Create a `.env` file for customization:

```env
LEASEWATCH_DATA_DIR=data
LEASEWATCH_LOG_LEVEL=INFO
LEASEWATCH_SERVER_PORT=8000
LEASEWATCH_SERVER_HOST=localhost
```

### Customizing Scrapers

To add new properties, create a new scraper in `src/scrapers/` following the pattern:

```python
async def scrape_new_property() -> List[FloorPlan]:
    # Your scraping logic here
    pass
```

Then add it to `main.py` in the data collection phase.

---

## ğŸ“ˆ Reports Available

1. **Daily Summary** - Overview of all scraped data
2. **Property Comparison** - Compare properties by price and value
3. **Bedroom Analysis** - Analysis by bedroom count
4. **Availability Report** - Current availability status
5. **Executive Summary** - Key metrics and KPIs

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ› Troubleshooting

### Common Issues

**Playwright browser not found:**
```bash
python -m playwright install chromium
```

**Permission errors:**
```bash
chmod +x main.py
```

**Import errors:**
```bash
# Make sure you're in the project directory and virtual environment is activated
source .venv/bin/activate
pip install -r requirements.txt
```

**No data returned:**
- Check if the websites are accessible
- Verify the scraper selectors are still valid
- Check the logs for specific error messages

### Debug Mode

Run with debug logging:
```python
# In main.py, change logger level
logger.setLevel(logging.DEBUG)
```

---

## ğŸ“ Support

- ğŸ“§ Email: [your-email@example.com]
- ğŸ› Issues: [GitHub Issues](https://github.com/lebjawi/LeaseWatch/issues)
- ğŸ“– Documentation: [GitHub Wiki](https://github.com/lebjawi/LeaseWatch/wiki)

---

**Happy apartment hunting! ğŸ âœ¨**
+-----------+------------+
            |
            v
+------------------------+
| Data Layer             |
| - Console Logs         |
| - JSON File (local)    |
| - Optional DB (future) |
+-----------+------------+
            |
            v
+------------------------+
| Report/Delivery Layer  |
| - Email                |
| - Webhook              |
+------------------------+
```

---

## ğŸ“ Project Structure

```
leasewatch/
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ camden.js
â”‚   â””â”€â”€ perimeter.js
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ report.js
â”‚   â””â”€â”€ storage.js
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger.js
â”œâ”€â”€ data/
â”‚   â””â”€â”€ prices.json
â”œâ”€â”€ index.js
â”œâ”€â”€ package.json
â”œâ”€â”€ render.yaml
â””â”€â”€ README.md
---

## ğŸš€ Development Roadmap

### ğŸŸ¢ Phase 1 â€“ Open Pages Daily (MVP)
**Goal:** Launch Puppeteer, navigate to each target apartment's main floor plan page.

- [x] Set up Puppeteer headless browser
- [ ] Navigate to target sites:
  - **Camden Dunwoody:** https://www.camdenliving.com/apartments/dunwoody-ga/camden-dunwoody/available-apartments
  - **Perimeter Gardens:** https://www.perimetergardens.com/interactivepropertymap
- [ ] Log success/failure
- [ ] Deploy to Render with daily cron job

### ğŸŸ¡ Phase 2 â€“ Extract Floor Plans & Prices
**Goal:** Scrape all 1B/1B and 2B/2B prices to console

- [ ] Parse floor plans on each site
- [ ] Filter by bed/bath configuration
- [ ] Extract plan name, price, and availability
- [ ] Output structured logs in console
- [ ] Save to `data/prices.json`

### ğŸŸ£ Phase 3 â€“ Generate & Deliver Reports
**Goal:** Automate reporting + delivery

- [ ] Format results into structured reports (JSON/CSV)
- [ ] Choose delivery method:
  - [ ] Send email (SendGrid integration)
  - [ ] Save to cloud folder (Dropbox, Google Drive API)
  - [ ] Optional: webhook/Slack/Discord
- [ ] Add timestamps to reports
- [ ] Optional: Create historical log file

---

## ğŸ› ï¸ Getting Started

### Prerequisites
- Node.js (v16 or higher)
- npm or yarn

### Local Development

1. **Clone the repository:**
   ```bash
   git clone https://github.com/your-username/leasewatch.git
   cd leasewatch
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Run the script locally:**
   ```bash
   node index.js
   ```

### Deployment on Render

1. Push code to GitHub
2. Log into [Render.com](https://render.com)
3. Create new "Background Worker" â†’ Link your repo
4. Add build/run command: `node index.js`
5. Set Cron Job schedule to `@daily`

---

## ğŸ“¦ Data Output Format

**Example output (Phase 2 & 3):**

```json
{
  "date": "2025-08-02T05:00:00Z",
  "camdenData": [
    {
      "name": "Dogwood",
      "beds": "1 Bed / 1 Bath",
      "price": "$1,480"
    },
    {
      "name": "Chestnut",
      "beds": "2 Bed / 2 Bath",
      "price": "$1,750"
    }
  ],
  "perimeterData": [
    {
      "name": "Concourse A2",
      "price": "$1,435",
      "availability": "Available Now"
    }
  ]
}
```

---

## ï¿½ Notifications (Phase 3)

Available delivery methods:
- ğŸ’Œ **Email** (SendGrid integration)
- ğŸ“¤ **Webhook** to Slack/Notion/Discord
- ğŸ§¾ **Local file** dump (JSON/CSV)

---

## ğŸ”’ Security

âš ï¸ **Important:** Store sensitive information using environment variables or `.env` files:
- SendGrid API keys
- Database credentials
- Webhook URLs

**Never hardcode credentials in your scripts.**

---

## ğŸ’¡ Future Enhancements

- [ ] Historical price trends & visualization
- [ ] Add more apartment communities
- [ ] Rent drop alerts
- [ ] Personal dashboard UI (React + Chart.js)
- [ ] Mobile app notifications
- [ ] Price prediction algorithms

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ§  About

Created with love and frustration by someone who refuses to get ripped off by rent hikes.

**LeaseWatch** aims to be the go-to automation tool for renters, real estate investors, and housing researchers who want **real-time, reliable** rental pricing updates.
ğŸŸ¢ Phase 1 â€“ Open Pages Daily (MVP)
Goal: Launch Puppeteer, navigate to each target apartment's main floor plan page.

 Set up Puppeteer headless browser

 Navigate to:

Camden Dunwoody: https://www.camdenliving.com/apartments/dunwoody-ga/camden-dunwoody/available-apartments

Perimeter Gardens: https://www.perimetergardens.com/interactivepropertymap

 Log success/failure

 Deploy to Render with daily cron job

ğŸŸ¡ Phase 2 â€“ Extract Floor Plans & Prices
Goal: Scrape all 1B/1B and 2B/2B prices to console

 Parse floor plans on each site

 Filter by bed/bath

 Extract plan name, price, and availability

 Output structured logs in console

 Save to data/prices.json

ğŸŸ£ Phase 3 â€“ Generate & Deliver Reports
Goal: Automate reporting + delivery to you

 Format results into report (JSON/CSV)

 Choose delivery method:

 Send email (e.g. via SendGrid)

 Save to cloud folder (Dropbox, Google Drive API)

 Optional: webhook/Slack/Discord

 Add timestamps to reports

 Optional: Create historical log file

ğŸ› ï¸ Local Development
1. Clone the repo:

git clone https://github.com/your-username/leasewatch.git
cd leasewatch
2. Install dependencies:

npm install
3. Run the script locally:

node index.js
â˜ï¸ Deploy to Render
Setup:
Push code to GitHub.

Log into Render.com

Create new â€œBackground Workerâ€ â†’ Link your repo

Add this build/run command:

node index.js
Set Cron Job schedule to @daily

ğŸ“¦ Output Format (Phase 2 & 3)

{
  "date": "2025-08-02T05:00:00Z",
  "camdenData": [
    {
      "name": "Dogwood",
      "beds": "1 Bed / 1 Bath",
      "price": "$1,480"
    },
    {
      "name": "Chestnut",
      "beds": "2 Bed / 2 Bath",
      "price": "$1,750"
    }
  ],
  "perimeterData": [
    {
      "name": "Concourse A2",
      "price": "$1,435",
      "availability": "Available Now"
    }
  ]
}
ğŸ“¬ Contact / Alerts (Coming Phase 3)
Youâ€™ll be able to receive daily reports:

ğŸ’Œ Email (SendGrid integration)

ğŸ“¤ Webhook to Slack/Notion/Discord

ğŸ§¾ Optional local file dump (JSON/CSV)

ğŸ”’ Security Note
Make sure to store secrets (like SendGrid API keys) using .env or environment variables on Render â€” never hardcode credentials in your scripts.

ğŸ’¡ Future Features
 Historical price trends & visualization

 Add more apartment communities

 Rent drop alerts

 Personal dashboard UI (React + Chart.js)

ğŸ§  Credits
Created with love and frustration by someone who refuses to get ripped off by rent hikes.

ğŸ“œ License
MIT License â€” open source and open for contribution.

---

Let me know if you'd like me to create the actual project boilerplate as a zip or GitHub-ready repo structure next.
